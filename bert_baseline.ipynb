{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_1W8CCma7i6",
        "outputId": "ae384e29-cdbb-466c-8b67-0e5595030957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.35.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.19.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/huggingface/transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHq25odfYoas",
        "outputId": "dfb7502d-a149-4c87-aceb-73cd92e54916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 342132, done.\u001b[K\n",
            "remote: Counting objects: 100% (490/490), done.\u001b[K\n",
            "remote: Compressing objects: 100% (206/206), done.\u001b[K\n",
            "remote: Total 342132 (delta 372), reused 284 (delta 284), pack-reused 341642 (from 3)\u001b[K\n",
            "Receiving objects: 100% (342132/342132), 357.53 MiB | 16.46 MiB/s, done.\n",
            "Resolving deltas: 100% (260271/260271), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/transformers\n",
        "!pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVzj4Xr2b44y",
        "outputId": "d3d98f2a-ea3f-4eb5-f18e-443362e50fbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/transformers\n",
            "Obtaining file:///content/transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.0.dev0) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.0.dev0) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.0.dev0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.0.dev0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.0.dev0) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.0.dev0) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.0.dev0) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.0.dev0) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.0.dev0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.0.dev0) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.0.dev0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.0.dev0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.0.dev0) (2025.8.3)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building editable for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.57.0.dev0-0.editable-py3-none-any.whl size=15057 sha256=0cdcc3f54fc152392e696620da843357bd1584de8c1a9bcae14bcc428ba3e649\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xa880irz/wheels/5d/95/aa/7bf76982b5186f967ea8b0d48a21290fa6c5c65b1e12ae5460\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.56.1\n",
            "    Uninstalling transformers-4.56.1:\n",
            "      Successfully uninstalled transformers-4.56.1\n",
            "Successfully installed transformers-4.57.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p data"
      ],
      "metadata": {
        "id": "eg4_eIjPYx_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O data/train-v1.1.json https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtruadYvZIK_",
        "outputId": "54635d5b-eaea-49b6-e49b-2ab25bbac908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-24 05:13:07--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30288272 (29M) [application/json]\n",
            "Saving to: ‘data/train-v1.1.json’\n",
            "\n",
            "data/train-v1.1.jso 100%[===================>]  28.88M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-09-24 05:13:10 (298 MB/s) - ‘data/train-v1.1.json’ saved [30288272/30288272]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O data/dev-v1.1.json  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNDGVmnQZIJc",
        "outputId": "856eba92-45c9-44ea-9a77-b95140fb7924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-24 05:13:12--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4854279 (4.6M) [application/json]\n",
            "Saving to: ‘data/dev-v1.1.json’\n",
            "\n",
            "data/dev-v1.1.json  100%[===================>]   4.63M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-09-24 05:13:13 (260 MB/s) - ‘data/dev-v1.1.json’ saved [4854279/4854279]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63mYwxnpero0",
        "outputId": "2e36b04e-82e8-4262-9907-325d52586f24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Collecting datasets\n",
            "  Downloading datasets-4.1.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.19.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Collecting pyarrow>=21.0.0 (from datasets)\n",
            "  Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.35.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-4.1.1-py3-none-any.whl (503 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.6/503.6 kB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyarrow, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
            "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-4.1.1 pyarrow-21.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/transformers/examples/pytorch/question-answering/run_qa.py \\\n",
        "  --model_name_or_path bert-base-uncased \\\n",
        "  --dataset_name squad \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --per_device_train_batch_size 12 \\\n",
        "  --per_device_eval_batch_size 16 \\\n",
        "  --learning_rate 3e-5 \\\n",
        "  --num_train_epochs 10 \\\n",
        "  --max_seq_length 320 \\\n",
        "  --doc_stride 128 \\\n",
        "  --output_dir data/bert-base-uncased-squad-v1 \\\n",
        "  --overwrite_output_dir \\\n",
        "  --logging_dir logs/ \\\n",
        "  --report_to none 2>&1 | tee train-bert-base.log\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GT9IwzBcZW7Q",
        "outputId": "3cf399c4-ac59-4cee-e176-ae422de110e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:__main__:Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "INFO:__main__:Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=True,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=None,\n",
            "eval_strategy=IntervalStrategy.NO,\n",
            "eval_use_gather_object=False,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_revision=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=no,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=3e-05,\n",
            "length_column_name=length,\n",
            "liger_kernel_config=None,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=logs/,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=10.0,\n",
            "optim=OptimizerNames.ADAMW_TORCH_FUSED,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=data/bert-base-uncased-squad-v1,\n",
            "overwrite_output_dir=True,\n",
            "parallelism_config=None,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=16,\n",
            "per_device_train_batch_size=12,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=[],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=None,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=SaveStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "Found cached dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/0.0.0/7b6d24c440a36b6815f21b70d25016731768db1f)\n",
            "INFO:datasets.builder:Found cached dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/0.0.0/7b6d24c440a36b6815f21b70d25016731768db1f)\n",
            "[INFO|configuration_utils.py:759] 2025-09-24 05:34:11,817 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
            "[INFO|configuration_utils.py:833] 2025-09-24 05:34:11,819 >> Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.57.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:759] 2025-09-24 05:34:12,071 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
            "[INFO|configuration_utils.py:833] 2025-09-24 05:34:12,072 >> Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.57.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2057] 2025-09-24 05:34:12,583 >> loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/vocab.txt\n",
            "[INFO|tokenization_utils_base.py:2057] 2025-09-24 05:34:12,583 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2057] 2025-09-24 05:34:12,583 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2057] 2025-09-24 05:34:12,583 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2057] 2025-09-24 05:34:12,583 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2057] 2025-09-24 05:34:12,583 >> loading file chat_template.jinja from cache at None\n",
            "[INFO|configuration_utils.py:759] 2025-09-24 05:34:12,583 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
            "[INFO|configuration_utils.py:833] 2025-09-24 05:34:12,584 >> Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.57.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:1205] 2025-09-24 05:34:12,650 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/model.safetensors\n",
            "[INFO|logging.py:343] 2025-09-24 05:34:12,671 >> A pretrained model of type `BertForQuestionAnswering` contains parameters that have been renamed internally (a few are listed below but more are present in the model):\n",
            "* `cls.predictions.transform.LayerNorm.beta` -> `cls.predictions.transform.LayerNorm.bias`\n",
            "* `cls.predictions.transform.LayerNorm.gamma` -> `cls.predictions.transform.LayerNorm.weight`\n",
            "If you are using a model from the Hub, consider submitting a PR to adjust these weights and help future users.\n",
            "[INFO|modeling_utils.py:5560] 2025-09-24 05:34:12,723 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:5572] 2025-09-24 05:34:12,723 >> Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/squad/plain_text/0.0.0/7b6d24c440a36b6815f21b70d25016731768db1f/cache-84eef40ba31ea6de_*_of_00001.arrow\n",
            "INFO:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/squad/plain_text/0.0.0/7b6d24c440a36b6815f21b70d25016731768db1f/cache-84eef40ba31ea6de_*_of_00001.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/squad/plain_text/0.0.0/7b6d24c440a36b6815f21b70d25016731768db1f/cache-52e21f5ef364dc7c_*_of_00001.arrow\n",
            "INFO:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/squad/plain_text/0.0.0/7b6d24c440a36b6815f21b70d25016731768db1f/cache-52e21f5ef364dc7c_*_of_00001.arrow\n",
            "[INFO|trainer.py:2519] 2025-09-24 05:34:14,621 >> ***** Running training *****\n",
            "[INFO|trainer.py:2520] 2025-09-24 05:34:14,622 >>   Num examples = 90,369\n",
            "[INFO|trainer.py:2521] 2025-09-24 05:34:14,622 >>   Num Epochs = 10\n",
            "[INFO|trainer.py:2522] 2025-09-24 05:34:14,622 >>   Instantaneous batch size per device = 12\n",
            "[INFO|trainer.py:2525] 2025-09-24 05:34:14,622 >>   Total train batch size (w. parallel, distributed & accumulation) = 12\n",
            "[INFO|trainer.py:2526] 2025-09-24 05:34:14,622 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:2527] 2025-09-24 05:34:14,622 >>   Total optimization steps = 75,310\n",
            "[INFO|trainer.py:2528] 2025-09-24 05:34:14,622 >>   Number of trainable parameters = 108,893,186\n",
            "  1%|          | 500/75310 [01:16<3:07:58,  6.63it/s][INFO|trainer.py:4308] 2025-09-24 05:35:30,841 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-500\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 05:35:30,843 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-500/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 05:35:31,538 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 05:35:31,539 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 05:35:31,539 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-500/special_tokens_map.json\n",
            "  1%|▏         | 1000/75310 [02:33<3:05:41,  6.67it/s][INFO|trainer.py:4308] 2025-09-24 05:36:47,746 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-1000\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 05:36:47,748 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-1000/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 05:36:48,429 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-1000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 05:36:48,430 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-1000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 05:36:48,430 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-1000/special_tokens_map.json\n",
            "  2%|▏         | 1500/75310 [03:49<3:04:36,  6.66it/s][INFO|trainer.py:4308] 2025-09-24 05:38:04,513 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-1500\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 05:38:04,515 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-1500/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 05:38:05,181 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-1500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 05:38:05,182 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-1500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 05:38:05,182 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-1500/special_tokens_map.json\n",
            "  3%|▎         | 2000/75310 [05:06<3:03:21,  6.66it/s][INFO|trainer.py:4308] 2025-09-24 05:39:21,321 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-2000\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 05:39:21,322 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-2000/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 05:39:22,004 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-2000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 05:39:22,005 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-2000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 05:39:22,005 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-2000/special_tokens_map.json\n",
            "  3%|▎         | 2500/75310 [06:23<3:02:20,  6.66it/s][INFO|trainer.py:4308] 2025-09-24 05:40:38,223 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-2500\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 05:40:38,225 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-2500/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 05:40:38,891 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-2500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 05:40:38,892 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-2500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 05:40:38,892 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-2500/special_tokens_map.json\n",
            "  4%|▍         | 3000/75310 [07:40<3:00:53,  6.66it/s][INFO|trainer.py:4308] 2025-09-24 05:41:55,001 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-3000\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 05:41:55,003 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-3000/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 05:41:55,682 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-3000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 05:41:55,683 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-3000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 05:41:55,683 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-3000/special_tokens_map.json\n",
            "  5%|▍         | 3500/75310 [08:57<2:59:25,  6.67it/s][INFO|trainer.py:4308] 2025-09-24 05:43:11,787 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-3500\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 05:43:11,789 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-3500/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 05:43:12,466 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-3500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 05:43:12,467 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-3500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 05:43:12,467 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-3500/special_tokens_map.json\n",
            "  5%|▌         | 4000/75310 [10:14<2:58:17,  6.67it/s][INFO|trainer.py:4308] 2025-09-24 05:44:28,657 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-4000\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 05:44:28,658 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-4000/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 05:44:29,346 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-4000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 05:44:29,347 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-4000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 05:44:29,347 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-4000/special_tokens_map.json\n",
            "  6%|▌         | 4500/75310 [11:30<2:57:13,  6.66it/s][INFO|trainer.py:4308] 2025-09-24 05:45:45,582 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-4500\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 05:45:45,584 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-4500/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 05:45:46,275 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-4500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 05:45:46,276 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-4500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 05:45:46,276 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-4500/special_tokens_map.json\n",
            "  7%|▋         | 5000/75310 [12:48<2:56:16,  6.65it/s][INFO|trainer.py:4308] 2025-09-24 05:47:02,775 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-5000\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 05:47:02,776 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-5000/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 05:47:03,498 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-5000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 05:47:03,499 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-5000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 05:47:03,499 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-5000/special_tokens_map.json\n",
            "  7%|▋         | 5500/75310 [14:05<2:54:32,  6.67it/s][INFO|trainer.py:4308] 2025-09-24 05:48:20,030 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-5500\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 05:48:20,032 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-5500/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 05:48:20,706 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-5500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 05:48:20,706 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-5500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 05:48:20,707 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-5500/special_tokens_map.json\n",
            "  8%|▊         | 6000/75310 [15:22<2:53:22,  6.66it/s][INFO|trainer.py:4308] 2025-09-24 05:49:36,812 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-6000\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 05:49:36,813 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-6000/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 05:49:37,487 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-6000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 05:49:37,488 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-6000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 05:49:37,488 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-6000/special_tokens_map.json\n",
            "  9%|▊         | 6500/75310 [16:39<2:52:24,  6.65it/s][INFO|trainer.py:4308] 2025-09-24 05:50:53,648 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-6500\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 05:50:53,650 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-6500/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 05:50:54,333 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-6500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 05:50:54,334 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-6500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 05:50:54,334 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-6500/special_tokens_map.json\n",
            "  9%|▉         | 7000/75310 [17:56<2:51:06,  6.65it/s][INFO|trainer.py:4308] 2025-09-24 05:52:10,666 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-7000\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 05:52:10,668 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-7000/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 05:52:11,338 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-7000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 05:52:11,339 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-7000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 05:52:11,339 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-7000/special_tokens_map.json\n",
            " 10%|▉         | 7500/75310 [19:12<2:50:23,  6.63it/s][INFO|trainer.py:4308] 2025-09-24 05:53:27,505 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-7500\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 05:53:27,507 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-7500/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 05:53:28,146 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-7500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 05:53:28,146 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-7500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 05:53:28,147 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-7500/special_tokens_map.json\n",
            " 11%|█         | 8000/75310 [20:29<2:47:54,  6.68it/s][INFO|trainer.py:4308] 2025-09-24 05:54:44,216 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-8000\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 05:54:44,217 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-8000/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 05:54:44,890 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-8000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 05:54:44,890 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-8000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 05:54:44,891 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-8000/special_tokens_map.json\n",
            " 11%|█▏        | 8500/75310 [21:46<2:47:14,  6.66it/s][INFO|trainer.py:4308] 2025-09-24 05:56:01,037 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-8500\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 05:56:01,038 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-8500/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 05:56:01,710 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-8500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 05:56:01,711 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-8500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 05:56:01,711 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-8500/special_tokens_map.json\n",
            " 12%|█▏        | 9000/75310 [23:05<2:45:55,  6.66it/s][INFO|trainer.py:4308] 2025-09-24 05:57:20,420 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-9000\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 05:57:20,421 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-9000/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 05:57:21,093 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-9000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 05:57:21,094 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-9000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 05:57:21,094 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-9000/special_tokens_map.json\n",
            " 13%|█▎        | 9500/75310 [24:22<2:44:57,  6.65it/s][INFO|trainer.py:4308] 2025-09-24 05:58:37,200 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-9500\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 05:58:37,201 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-9500/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 05:58:37,768 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-9500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 05:58:37,769 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-9500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 05:58:37,769 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-9500/special_tokens_map.json\n",
            " 13%|█▎        | 10000/75310 [25:39<2:43:33,  6.66it/s][INFO|trainer.py:4308] 2025-09-24 05:59:54,310 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-10000\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 05:59:54,312 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-10000/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 05:59:55,005 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-10000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 05:59:55,006 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-10000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 05:59:55,007 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-10000/special_tokens_map.json\n",
            " 14%|█▍        | 10500/75310 [26:56<2:42:45,  6.64it/s][INFO|trainer.py:4308] 2025-09-24 06:01:11,229 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-10500\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:01:11,230 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-10500/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:01:11,901 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-10500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:01:11,902 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-10500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:01:11,902 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-10500/special_tokens_map.json\n",
            " 15%|█▍        | 11000/75310 [28:13<2:40:50,  6.66it/s][INFO|trainer.py:4308] 2025-09-24 06:02:28,011 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-11000\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:02:28,013 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-11000/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:02:28,697 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-11000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:02:28,698 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-11000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:02:28,698 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-11000/special_tokens_map.json\n",
            " 15%|█▌        | 11500/75310 [29:30<2:39:37,  6.66it/s][INFO|trainer.py:4308] 2025-09-24 06:03:44,910 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-11500\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:03:44,912 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-11500/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:03:45,607 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-11500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:03:45,608 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-11500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:03:45,608 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-11500/special_tokens_map.json\n",
            " 16%|█▌        | 12000/75310 [30:47<2:38:28,  6.66it/s][INFO|trainer.py:4308] 2025-09-24 06:05:02,148 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-12000\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:05:02,150 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-12000/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:05:02,841 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-12000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:05:02,842 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-12000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:05:02,842 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-12000/special_tokens_map.json\n",
            " 17%|█▋        | 12500/75310 [32:04<2:37:13,  6.66it/s][INFO|trainer.py:4308] 2025-09-24 06:06:19,038 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-12500\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:06:19,039 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-12500/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:06:19,724 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-12500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:06:19,725 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-12500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:06:19,726 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-12500/special_tokens_map.json\n",
            " 17%|█▋        | 13000/75310 [33:21<2:35:34,  6.68it/s][INFO|trainer.py:4308] 2025-09-24 06:07:35,888 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-13000\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:07:35,890 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-13000/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:07:36,573 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-13000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:07:36,574 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-13000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:07:36,574 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-13000/special_tokens_map.json\n",
            " 18%|█▊        | 13500/75310 [34:38<2:34:32,  6.67it/s][INFO|trainer.py:4308] 2025-09-24 06:08:52,704 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-13500\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:08:52,706 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-13500/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:08:53,373 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-13500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:08:53,374 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-13500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:08:53,374 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-13500/special_tokens_map.json\n",
            " 19%|█▊        | 14000/75310 [35:54<2:33:29,  6.66it/s][INFO|trainer.py:4308] 2025-09-24 06:10:09,480 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-14000\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:10:09,481 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-14000/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:10:10,146 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-14000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:10:10,147 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-14000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:10:10,147 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-14000/special_tokens_map.json\n",
            " 19%|█▉        | 14500/75310 [37:11<2:32:10,  6.66it/s][INFO|trainer.py:4308] 2025-09-24 06:11:26,481 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-14500\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:11:26,483 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-14500/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:11:27,176 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-14500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:11:27,177 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-14500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:11:27,177 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-14500/special_tokens_map.json\n",
            " 20%|█▉        | 15000/75310 [38:28<2:30:50,  6.66it/s][INFO|trainer.py:4308] 2025-09-24 06:12:43,432 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-15000\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:12:43,434 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-15000/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:12:44,118 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-15000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:12:44,119 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-15000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:12:44,120 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-15000/special_tokens_map.json\n",
            " 21%|██        | 15500/75310 [39:45<2:30:01,  6.64it/s][INFO|trainer.py:4308] 2025-09-24 06:14:00,212 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-15500\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:14:00,213 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-15500/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:14:00,873 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-15500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:14:00,874 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-15500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:14:00,874 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-15500/special_tokens_map.json\n",
            " 21%|██        | 16000/75310 [41:02<2:28:38,  6.65it/s][INFO|trainer.py:4308] 2025-09-24 06:15:17,266 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-16000\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:15:17,268 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-16000/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:15:17,947 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-16000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:15:17,948 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-16000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:15:17,948 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-16000/special_tokens_map.json\n",
            " 22%|██▏       | 16500/75310 [42:19<2:27:51,  6.63it/s][INFO|trainer.py:4308] 2025-09-24 06:16:34,129 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-16500\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:16:34,131 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-16500/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:16:34,828 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-16500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:16:34,829 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-16500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:16:34,829 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-16500/special_tokens_map.json\n",
            " 23%|██▎       | 17000/75310 [43:36<2:26:16,  6.64it/s][INFO|trainer.py:4308] 2025-09-24 06:17:51,305 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-17000\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:17:51,307 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-17000/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:17:52,046 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-17000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:17:52,047 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-17000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:17:52,048 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-17000/special_tokens_map.json\n",
            " 23%|██▎       | 17500/75310 [44:53<2:24:38,  6.66it/s][INFO|trainer.py:4308] 2025-09-24 06:19:08,368 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-17500\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:19:08,369 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-17500/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:19:09,036 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-17500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:19:09,037 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-17500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:19:09,037 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-17500/special_tokens_map.json\n",
            " 24%|██▍       | 18000/75310 [46:10<2:23:40,  6.65it/s][INFO|trainer.py:4308] 2025-09-24 06:20:25,374 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-18000\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:20:25,376 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-18000/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:20:26,060 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-18000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:20:26,060 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-18000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:20:26,061 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-18000/special_tokens_map.json\n",
            " 25%|██▍       | 18500/75310 [47:27<2:22:15,  6.66it/s][INFO|trainer.py:4308] 2025-09-24 06:21:42,373 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-18500\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:21:42,375 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-18500/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:21:43,069 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-18500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:21:43,070 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-18500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:21:43,070 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-18500/special_tokens_map.json\n",
            " 25%|██▌       | 19000/75310 [48:44<2:21:19,  6.64it/s][INFO|trainer.py:4308] 2025-09-24 06:22:59,421 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-19000\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:22:59,423 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-19000/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:23:00,113 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-19000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:23:00,114 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-19000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:23:00,114 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-19000/special_tokens_map.json\n",
            " 26%|██▌       | 19500/75310 [50:01<2:19:55,  6.65it/s][INFO|trainer.py:4308] 2025-09-24 06:24:16,306 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-19500\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:24:16,308 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-19500/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:24:16,855 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-19500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:24:16,856 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-19500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:24:16,856 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-19500/special_tokens_map.json\n",
            " 27%|██▋       | 20000/75310 [51:18<2:18:31,  6.65it/s][INFO|trainer.py:4308] 2025-09-24 06:25:33,079 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-20000\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:25:33,080 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-20000/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:25:33,751 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-20000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:25:33,751 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-20000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:25:33,752 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-20000/special_tokens_map.json\n",
            " 27%|██▋       | 20500/75310 [52:35<2:17:13,  6.66it/s][INFO|trainer.py:4308] 2025-09-24 06:26:49,914 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-20500\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:26:49,916 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-20500/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:26:50,607 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-20500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:26:50,608 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-20500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:26:50,609 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-20500/special_tokens_map.json\n",
            " 28%|██▊       | 21000/75310 [53:52<2:16:30,  6.63it/s][INFO|trainer.py:4308] 2025-09-24 06:28:06,849 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-21000\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:28:06,851 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-21000/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:28:07,539 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-21000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:28:07,540 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-21000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:28:07,540 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-21000/special_tokens_map.json\n",
            " 29%|██▊       | 21500/75310 [55:09<2:15:01,  6.64it/s][INFO|trainer.py:4308] 2025-09-24 06:29:23,700 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-21500\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:29:23,702 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-21500/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:29:24,392 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-21500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:29:24,393 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-21500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:29:24,393 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-21500/special_tokens_map.json\n",
            " 29%|██▉       | 22000/75310 [56:26<2:13:30,  6.65it/s][INFO|trainer.py:4308] 2025-09-24 06:30:40,677 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-22000\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:30:40,678 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-22000/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:30:41,361 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-22000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:30:41,362 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-22000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:30:41,362 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-22000/special_tokens_map.json\n",
            " 30%|██▉       | 22500/75310 [57:43<2:12:07,  6.66it/s][INFO|trainer.py:4308] 2025-09-24 06:31:57,693 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-22500\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:31:57,695 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-22500/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:31:58,360 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-22500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:31:58,361 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-22500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:31:58,362 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-22500/special_tokens_map.json\n",
            " 31%|███       | 23000/75310 [58:59<2:11:03,  6.65it/s][INFO|trainer.py:4308] 2025-09-24 06:33:14,543 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-23000\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:33:14,545 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-23000/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:33:15,230 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-23000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:33:15,231 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-23000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:33:15,231 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-23000/special_tokens_map.json\n",
            " 31%|███       | 23500/75310 [1:00:16<2:10:03,  6.64it/s][INFO|trainer.py:4308] 2025-09-24 06:34:31,504 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-23500\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:34:31,505 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-23500/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:34:32,146 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-23500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:34:32,147 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-23500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:34:32,147 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-23500/special_tokens_map.json\n",
            " 32%|███▏      | 24000/75310 [1:01:33<2:08:50,  6.64it/s][INFO|trainer.py:4308] 2025-09-24 06:35:48,470 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-24000\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:35:48,472 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-24000/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:35:49,175 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-24000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:35:49,176 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-24000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:35:49,176 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-24000/special_tokens_map.json\n",
            " 33%|███▎      | 24500/75310 [1:02:50<2:07:38,  6.63it/s][INFO|trainer.py:4308] 2025-09-24 06:37:05,577 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-24500\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:37:05,578 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-24500/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:37:06,275 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-24500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:37:06,276 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-24500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:37:06,276 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-24500/special_tokens_map.json\n",
            " 33%|███▎      | 25000/75310 [1:04:07<2:06:06,  6.65it/s][INFO|trainer.py:4308] 2025-09-24 06:38:22,566 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-25000\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:38:22,568 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-25000/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:38:23,259 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-25000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:38:23,260 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-25000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:38:23,260 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-25000/special_tokens_map.json\n",
            " 34%|███▍      | 25500/75310 [1:05:24<2:05:06,  6.64it/s][INFO|trainer.py:4308] 2025-09-24 06:39:39,559 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-25500\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:39:39,561 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-25500/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:39:40,240 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-25500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:39:40,241 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-25500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:39:40,241 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-25500/special_tokens_map.json\n",
            " 35%|███▍      | 26000/75310 [1:06:41<2:03:24,  6.66it/s][INFO|trainer.py:4308] 2025-09-24 06:40:56,536 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-26000\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:40:56,538 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-26000/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:40:57,229 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-26000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:40:57,230 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-26000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:40:57,230 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-26000/special_tokens_map.json\n",
            " 35%|███▌      | 26500/75310 [1:07:59<2:02:14,  6.66it/s][INFO|trainer.py:4308] 2025-09-24 06:42:13,811 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-26500\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:42:13,812 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-26500/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:42:14,534 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-26500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:42:14,535 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-26500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:42:14,535 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-26500/special_tokens_map.json\n",
            " 36%|███▌      | 27000/75310 [1:09:16<2:00:58,  6.66it/s][INFO|trainer.py:4308] 2025-09-24 06:43:30,784 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-27000\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:43:30,785 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-27000/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:43:31,470 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-27000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:43:31,471 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-27000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:43:31,471 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-27000/special_tokens_map.json\n",
            " 37%|███▋      | 27500/75310 [1:10:32<1:59:34,  6.66it/s][INFO|trainer.py:4308] 2025-09-24 06:44:47,568 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-27500\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:44:47,570 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-27500/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:44:48,196 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-27500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:44:48,197 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-27500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:44:48,197 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-27500/special_tokens_map.json\n",
            " 37%|███▋      | 28000/75310 [1:11:49<1:58:21,  6.66it/s][INFO|trainer.py:4308] 2025-09-24 06:46:04,469 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-28000\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:46:04,470 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-28000/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:46:05,151 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-28000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:46:05,152 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-28000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:46:05,152 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-28000/special_tokens_map.json\n",
            " 38%|███▊      | 28500/75310 [1:13:06<1:57:33,  6.64it/s][INFO|trainer.py:4308] 2025-09-24 06:47:21,479 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-28500\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:47:21,481 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-28500/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:47:22,180 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-28500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:47:22,181 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-28500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:47:22,181 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-28500/special_tokens_map.json\n",
            " 39%|███▊      | 29000/75310 [1:14:23<1:55:55,  6.66it/s][INFO|trainer.py:4308] 2025-09-24 06:48:38,440 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-29000\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:48:38,441 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-29000/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:48:39,138 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-29000/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:48:39,139 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-29000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:48:39,139 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-29000/special_tokens_map.json\n",
            " 39%|███▉      | 29500/75310 [1:15:40<1:55:02,  6.64it/s][INFO|trainer.py:4308] 2025-09-24 06:49:55,494 >> Saving model checkpoint to data/bert-base-uncased-squad-v1/checkpoint-29500\n",
            "[INFO|configuration_utils.py:485] 2025-09-24 06:49:55,495 >> Configuration saved in data/bert-base-uncased-squad-v1/checkpoint-29500/config.json\n",
            "[INFO|modeling_utils.py:4206] 2025-09-24 06:49:56,170 >> Model weights saved in data/bert-base-uncased-squad-v1/checkpoint-29500/model.safetensors\n",
            "[INFO|tokenization_utils_base.py:2552] 2025-09-24 06:49:56,171 >> tokenizer config file saved in data/bert-base-uncased-squad-v1/checkpoint-29500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2561] 2025-09-24 06:49:56,171 >> Special tokens file saved in data/bert-base-uncased-squad-v1/checkpoint-29500/special_tokens_map.json\n",
            "{'loss': 2.393, 'grad_norm': 18.064695358276367, 'learning_rate': 2.9801221617315097e-05, 'epoch': 0.07}\n",
            "{'loss': 1.5762, 'grad_norm': 17.879762649536133, 'learning_rate': 2.960204488115788e-05, 'epoch': 0.13}\n",
            "{'loss': 1.3964, 'grad_norm': 13.491644859313965, 'learning_rate': 2.9402868145000665e-05, 'epoch': 0.2}\n",
            "{'loss': 1.2778, 'grad_norm': 22.751371383666992, 'learning_rate': 2.9203691408843446e-05, 'epoch': 0.27}\n",
            "{'loss': 1.2444, 'grad_norm': 23.909894943237305, 'learning_rate': 2.900451467268623e-05, 'epoch': 0.33}\n",
            "{'loss': 1.1918, 'grad_norm': 10.352919578552246, 'learning_rate': 2.8805337936529013e-05, 'epoch': 0.4}\n",
            "{'loss': 1.1896, 'grad_norm': 8.734155654907227, 'learning_rate': 2.8606161200371797e-05, 'epoch': 0.46}\n",
            "{'loss': 1.1675, 'grad_norm': 15.62720012664795, 'learning_rate': 2.840698446421458e-05, 'epoch': 0.53}\n",
            "{'loss': 1.1212, 'grad_norm': 14.632026672363281, 'learning_rate': 2.8207807728057365e-05, 'epoch': 0.6}\n",
            "{'loss': 1.1101, 'grad_norm': 23.38295555114746, 'learning_rate': 2.8008630991900145e-05, 'epoch': 0.66}\n",
            "{'loss': 1.0767, 'grad_norm': 22.753034591674805, 'learning_rate': 2.780945425574293e-05, 'epoch': 0.73}\n",
            "{'loss': 1.1046, 'grad_norm': 13.11349105834961, 'learning_rate': 2.7610277519585713e-05, 'epoch': 0.8}\n",
            "{'loss': 1.0677, 'grad_norm': 18.82762336730957, 'learning_rate': 2.7411100783428497e-05, 'epoch': 0.86}\n",
            "{'loss': 1.0409, 'grad_norm': 14.322486877441406, 'learning_rate': 2.7211924047271278e-05, 'epoch': 0.93}\n",
            "{'loss': 1.0688, 'grad_norm': 17.881404876708984, 'learning_rate': 2.701274731111406e-05, 'epoch': 1.0}\n",
            "{'loss': 0.7534, 'grad_norm': 12.557842254638672, 'learning_rate': 2.681357057495685e-05, 'epoch': 1.06}\n",
            "{'loss': 0.7763, 'grad_norm': 27.140947341918945, 'learning_rate': 2.661439383879963e-05, 'epoch': 1.13}\n",
            "{'loss': 0.7582, 'grad_norm': 19.06298828125, 'learning_rate': 2.6415217102642413e-05, 'epoch': 1.2}\n",
            "{'loss': 0.7636, 'grad_norm': 30.890926361083984, 'learning_rate': 2.6216040366485197e-05, 'epoch': 1.26}\n",
            "{'loss': 0.7624, 'grad_norm': 22.075315475463867, 'learning_rate': 2.6016863630327977e-05, 'epoch': 1.33}\n",
            "{'loss': 0.769, 'grad_norm': 12.31218433380127, 'learning_rate': 2.581768689417076e-05, 'epoch': 1.39}\n",
            "{'loss': 0.776, 'grad_norm': 17.24026870727539, 'learning_rate': 2.5618510158013545e-05, 'epoch': 1.46}\n",
            "{'loss': 0.7616, 'grad_norm': 14.547136306762695, 'learning_rate': 2.5419333421856326e-05, 'epoch': 1.53}\n",
            "{'loss': 0.7627, 'grad_norm': 25.321945190429688, 'learning_rate': 2.522015668569911e-05, 'epoch': 1.59}\n",
            "{'loss': 0.7431, 'grad_norm': 12.12589168548584, 'learning_rate': 2.5020979949541897e-05, 'epoch': 1.66}\n",
            "{'loss': 0.7666, 'grad_norm': 27.23340606689453, 'learning_rate': 2.4821803213384677e-05, 'epoch': 1.73}\n",
            "{'loss': 0.7552, 'grad_norm': 23.184864044189453, 'learning_rate': 2.462262647722746e-05, 'epoch': 1.79}\n",
            "{'loss': 0.7534, 'grad_norm': 11.127357482910156, 'learning_rate': 2.4423449741070245e-05, 'epoch': 1.86}\n",
            "{'loss': 0.7591, 'grad_norm': 16.431255340576172, 'learning_rate': 2.4224273004913025e-05, 'epoch': 1.93}\n",
            "{'loss': 0.7805, 'grad_norm': 17.069412231445312, 'learning_rate': 2.402509626875581e-05, 'epoch': 1.99}\n",
            "{'loss': 0.5196, 'grad_norm': 8.188584327697754, 'learning_rate': 2.3825919532598593e-05, 'epoch': 2.06}\n",
            "{'loss': 0.4972, 'grad_norm': 7.450684070587158, 'learning_rate': 2.3626742796441374e-05, 'epoch': 2.12}\n",
            "{'loss': 0.5029, 'grad_norm': 21.30292320251465, 'learning_rate': 2.3427566060284158e-05, 'epoch': 2.19}\n",
            "{'loss': 0.5021, 'grad_norm': 21.983922958374023, 'learning_rate': 2.3228389324126945e-05, 'epoch': 2.26}\n",
            "{'loss': 0.5207, 'grad_norm': 15.41193962097168, 'learning_rate': 2.3029212587969725e-05, 'epoch': 2.32}\n",
            "{'loss': 0.5079, 'grad_norm': 11.493807792663574, 'learning_rate': 2.283003585181251e-05, 'epoch': 2.39}\n",
            "{'loss': 0.5158, 'grad_norm': 24.417461395263672, 'learning_rate': 2.2630859115655293e-05, 'epoch': 2.46}\n",
            "{'loss': 0.528, 'grad_norm': 12.964244842529297, 'learning_rate': 2.2431682379498074e-05, 'epoch': 2.52}\n",
            "{'loss': 0.5302, 'grad_norm': 10.897726058959961, 'learning_rate': 2.2232505643340857e-05, 'epoch': 2.59}\n",
            "{'loss': 0.5099, 'grad_norm': 7.155827045440674, 'learning_rate': 2.203332890718364e-05, 'epoch': 2.66}\n",
            "{'loss': 0.5312, 'grad_norm': 18.321035385131836, 'learning_rate': 2.1834152171026425e-05, 'epoch': 2.72}\n",
            "{'loss': 0.5024, 'grad_norm': 18.48708724975586, 'learning_rate': 2.1634975434869206e-05, 'epoch': 2.79}\n",
            "{'loss': 0.5294, 'grad_norm': 21.538745880126953, 'learning_rate': 2.1435798698711993e-05, 'epoch': 2.85}\n",
            "{'loss': 0.5194, 'grad_norm': 10.050749778747559, 'learning_rate': 2.1236621962554777e-05, 'epoch': 2.92}\n",
            "{'loss': 0.5319, 'grad_norm': 14.188606262207031, 'learning_rate': 2.1037445226397557e-05, 'epoch': 2.99}\n",
            "{'loss': 0.3551, 'grad_norm': 5.768698215484619, 'learning_rate': 2.083826849024034e-05, 'epoch': 3.05}\n",
            "{'loss': 0.3377, 'grad_norm': 14.945510864257812, 'learning_rate': 2.0639091754083125e-05, 'epoch': 3.12}\n",
            "{'loss': 0.3182, 'grad_norm': 19.318099975585938, 'learning_rate': 2.0439915017925906e-05, 'epoch': 3.19}\n",
            "{'loss': 0.3253, 'grad_norm': 17.260766983032227, 'learning_rate': 2.024073828176869e-05, 'epoch': 3.25}\n",
            "{'loss': 0.338, 'grad_norm': 46.482303619384766, 'learning_rate': 2.0041561545611473e-05, 'epoch': 3.32}\n",
            "{'loss': 0.3447, 'grad_norm': 17.414695739746094, 'learning_rate': 1.9842384809454254e-05, 'epoch': 3.39}\n",
            "{'loss': 0.3546, 'grad_norm': 20.938121795654297, 'learning_rate': 1.964320807329704e-05, 'epoch': 3.45}\n",
            "{'loss': 0.3263, 'grad_norm': 8.430502891540527, 'learning_rate': 1.9444031337139825e-05, 'epoch': 3.52}\n",
            "{'loss': 0.3699, 'grad_norm': 59.57076644897461, 'learning_rate': 1.9244854600982605e-05, 'epoch': 3.59}\n",
            "{'loss': 0.3529, 'grad_norm': 17.85848617553711, 'learning_rate': 1.904567786482539e-05, 'epoch': 3.65}\n",
            "{'loss': 0.3491, 'grad_norm': 10.478082656860352, 'learning_rate': 1.8846501128668173e-05, 'epoch': 3.72}\n",
            "{'loss': 0.3628, 'grad_norm': 20.334247589111328, 'learning_rate': 1.8647324392510954e-05, 'epoch': 3.78}\n",
            "{'loss': 0.3519, 'grad_norm': 10.995564460754395, 'learning_rate': 1.8448147656353738e-05, 'epoch': 3.85}\n",
            "{'loss': 0.3601, 'grad_norm': 10.948431015014648, 'learning_rate': 1.824897092019652e-05, 'epoch': 3.92}\n",
            "tee: train-bert-base.log: No space left on device\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 967, in save\n",
            "    _save(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 1268, in _save\n",
            "    zip_file.write_record(name, storage, num_bytes)\n",
            "RuntimeError: [enforce fail at inline_container.cc:858] . PytorchStreamWriter failed writing file data/143: file write failed\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/transformers/examples/pytorch/question-answering/run_qa.py\", line 714, in <module>\n",
            "    main()\n",
            "  File \"/content/transformers/examples/pytorch/question-answering/run_qa.py\", line 655, in main\n",
            "    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/transformers/src/transformers/trainer.py\", line 2325, in train\n",
            "    return inner_training_loop(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/transformers/src/transformers/trainer.py\", line 2756, in _inner_training_loop\n",
            "    self._maybe_log_save_evaluate(\n",
            "  File \"/content/transformers/src/transformers/trainer.py\", line 3236, in _maybe_log_save_evaluate\n",
            "    self._save_checkpoint(model, trial)\n",
            "  File \"/content/transformers/src/transformers/trainer.py\", line 3344, in _save_checkpoint\n",
            "    self._save_optimizer_and_scheduler(output_dir)\n",
            "  File \"/content/transformers/src/transformers/trainer.py\", line 3471, in _save_optimizer_and_scheduler\n",
            "    torch.save(self.optimizer.state_dict(), os.path.join(output_dir, OPTIMIZER_NAME))\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 966, in save\n",
            "    with _open_zipfile_writer(f) as opened_zipfile:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/serialization.py\", line 798, in __exit__\n",
            "    self.file_like.write_end_of_file()\n",
            "RuntimeError: [enforce fail at inline_container.cc:664] . unexpected pos 598916160 vs 598916048\n",
            " 39%|███▉      | 29500/75310 [1:15:43<1:57:34,  6.49it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zHsHUeXxbf5O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}